import requests
import json

# Connection Details
GRAFANA_URL = "https://your-grafana-link.com"
USER = "your_id"
PASS = "your_pass"

# This payload mimics the "Query Inspector" from your image
payload = {
    "queries": [{
        "refId": "A",
        "datasource": {"uid": "your_ds_uid"}, # Find this in your Inspector
        "rawSql": "SELECT start_time_ts, status FROM dbq.process_schedule WHERE start_time_ts > now() - interval '1 hour'",
        "format": "table"
    }],
    "from": "now-1h", "to": "now"
}

def fetch_and_parse():
    response = requests.post(f"{GRAFANA_URL}/api/ds/query", auth=(USER, PASS), json=payload)
    
    if response.status_code != 200:
        print(f"Error: {response.status_code}")
        return

    data = response.json()
    
    # 1. Drill down to the data frame
    frame = data['results']['A']['frames'][0]
    
    # 2. Extract column names from schema
    columns = [field['name'] for field in frame['schema']['fields']]
    
    # 3. Extract the actual values
    # In Grafana, values are stored as a list of lists: [[times...], [status1...], [status2...]]
    values = frame['data']['values']
    
    # 4. Transpose the data so it's readable row-by-row
    rows = list(zip(*values))
    
    print(f"{' | '.join(columns)}")
    print("-" * 50)
    for row in rows:
        print(f"{row}")

fetch_and_parse()
====================
part 2 inclding llm

import requests
import json
from openai import AzureOpenAI

# --- CONFIGURATION ---
GRAFANA_URL = "https://dbq-dev-grafana.p2.ocp.citizensbank.com"
# Use a Service Account Token or your credentials
USER = "your_userid"
PASS = "your_password"

client = AzureOpenAI(
    azure_endpoint="https://your-resource.openai.azure.com/", 
    api_key="your_azure_open_ai_key", 
    api_version="2024-02-01"
)

# 1. Prepare the Query Payload (Based on your "Query Inspector" image)
# Note: I am using the raw SQL seen in your screenshot
sql_query = """
SELECT 
    ps.start_time_ts,
    MAX(CASE WHEN ps.process_id = 11 THEN ps.status END) AS "Metrics Exporter Events",
    MAX(CASE WHEN ps.process_id = 12 THEN ps.status END) AS "Metrics Exporter Allocations",
    MAX(CASE WHEN ps.process_id = 13 THEN ps.status END) AS "Resource Collector"
FROM dbq.process_schedule ps
JOIN dbq.process p ON ps.process_id = p.process_id
WHERE ps.start_time_ts BETWEEN 'now-30m' AND 'now'
GROUP BY ps.start_time_ts
ORDER BY ps.start_time_ts;
"""

payload = {
    "queries": [
        {
            "refId": "A",
            "datasource": {"type": "grafana-postgresql-datasource", "uid": "your_ds_uid"},
            "rawSql": sql_query,
            "format": "table"
        }
    ],
    "from": "now-30m",
    "to": "now"
}

# 2. Fetch Data
print("üì° Fetching data from Grafana...")
response = requests.post(
    f"{GRAFANA_URL}/api/ds/query", 
    auth=(USER, PASS), 
    json=payload
)

# 3. Clean the data for the LLM
# Instead of sending the whole JSON, we extract the frames
data = response.json()
frames = data.get('results', {}).get('A', {}).get('frames', [])

# Convert the data into a simple string format the LLM can easily read
data_summary = ""
for frame in frames:
    data_summary += str(frame.get('data', {}).get('values', []))

# 4. Get LLM Response
print("ü§ñ Analyzing with LLM...")
prompt = f"""
You are a Site Reliability Engineer. Look at this status data for our microservices:
{data_summary}

Tasks:
1. Identify if any process (Metrics Exporter, Resource Collector) is currently 'FAILED' or 'DOWN'.
2. Provide a summary of the system health over the last 30 minutes.
"""

analysis = client.chat.completions.create(
    model="your-deployment-name",
    messages=[{"role": "user", "content": prompt}]
)

print("\n--- HEALTH REPORT ---")
print(analysis.choices[0].message.content)

============================================

import requests
import json
from openai import AzureOpenAI

# --- CONFIGURATION ---
GRAFANA_URL = "https://your-grafana-link.com"
DASHBOARD_UID = "paste_uid_from_url_here" # e.g. 'c8f641f5'
USER = "your_userid"
PASS = "your_password"

# Azure OpenAI Config
client = AzureOpenAI(
    azure_endpoint="https://your-resource.openai.azure.com/", 
    api_key="your_azure_open_ai_key", api_version="2024-02-01"
)

# 1. Direct Pickup: Get Dashboard JSON
print("üîç Accessing Dashboard...")
dash_resp = requests.get(f"{GRAFANA_URL}/api/dashboards/uid/{DASHBOARD_UID}", auth=(USER, PASS))
dashboard = dash_resp.json()

# 2. Extract Query from the "Process schedule" panel
target_panel_title = "Process schedule" # Match your panel name exactly
found_query = None
datasource_uid = None

for panel in dashboard['dashboard']['panels']:
    if panel.get('title') == target_panel_title:
        found_query = panel['targets'][0].get('rawSql') # or 'expr' for Prometheus
        datasource_uid = panel['datasource'].get('uid')
        break

if not found_query:
    print("‚ùå Could not find the panel. Check the title name.")
    exit()

print(f"‚úÖ Found Query: {found_query[:50]}...")

# 3. Execute the Query
query_payload = {
    "queries": [{"refId": "A", "datasource": {"uid": datasource_uid}, "rawSql": found_query}],
    "from": "now-1h", "to": "now"
}
data_resp = requests.post(f"{GRAFANA_URL}/api/ds/query", auth=(USER, PASS), json=query_payload)

# 4. Analyze with Azure OpenAI
print("ü§ñ Asking Azure OpenAI to review the failure...")
analysis = client.chat.completions.create(
    model="your-deployment",
    messages=[{"role": "user", "content": f"Review this Grafana DB response and tell me why it is failing/red:\n{data_resp.text}"}]
)

print("\n--- AI DIAGNOSIS ---")
print(analysis.choices[0].message.content)
